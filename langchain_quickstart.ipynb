{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a92e878-a161-4286-9cb4-fe86e4ed7dd0",
   "metadata": {},
   "source": [
    "# Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d844a-d0fb-416c-8759-ee607ce7428a",
   "metadata": {},
   "source": [
    "Tutorial criando uma LLM chain basic, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9cda37e-7aa2-472b-a945-3672399c0a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in a number of ways:\\n\\n1. **Automated Testing**: Langsmith can be used to automate the testing process. You can use Langsmith to write test cases and then use its natural language processing capabilities to automatically generate test data and test scripts. This can save a lot of time and effort in the testing process.\\n\\n2. **Natural Language Understanding**: Langsmith's advanced natural language understanding capabilities can be leveraged to create more effective test cases. You can use natural language to describe the test scenarios and Langsmith can understand and interpret these scenarios to generate the appropriate test cases.\\n\\n3. **Test Data Generation**: Langsmith can generate test data that is more realistic and relevant to your specific use case. By using natural language processing, Langsmith can understand the context and generate data that is meaningful and useful for testing.\\n\\n4. **Test Coverage Analysis**: Langsmith can analyze your test coverage and identify areas that may be lacking sufficient test coverage. By understanding the natural language used in your test cases, Langsmith can provide insights into areas that may need additional testing.\\n\\n5. **Bug Reporting and Tracking**: Langsmith can understand and interpret bug reports written in natural language. It can automatically create bug tickets, assign them to the appropriate team members, and track their progress. This helps streamline the bug fixing process and ensures that issues are resolved efficiently.\\n\\n6. **User Acceptance Testing**: Langsmith can facilitate user acceptance testing (UAT) by enabling stakeholders to provide feedback and input in natural language. Langsmith can then interpret this feedback and provide it to the development team in a structured format, making it easier to address user concerns and requirements.\\n\\n7. **Documentation and Knowledge Base**: Langsmith can be used to create and maintain testing documentation and knowledge bases. It can automatically generate how-to guides, FAQs, and other documentation based on the knowledge it acquires during the testing process. This helps ensure that the team has access to up-to-date and accurate information.\\n\\nOverall, Langsmith's natural language processing capabilities can bring a number of benefits to the testing process, making it more efficient, effective, and accessible to stakeholders.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2810a169-ea97-41e4-b33c-221c689a22df', 'token_count': {'input_tokens': 74, 'output_tokens': 439}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2810a169-ea97-41e4-b33c-221c689a22df', 'token_count': {'input_tokens': 74, 'output_tokens': 439}}, id='run-21595938-bcf3-42e2-9d20-502f33ea0e42-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "llm = ChatCohere()\n",
    "llm.invoke(\"how can langsmith help with testing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7843b10c-f697-4217-b164-3e682100051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is a powerful tool that can greatly assist with testing and quality assurance processes, especially for software products with a user interface or natural language processing capabilities. Here's how Langsmith can help with testing:\\n\\n1. **User Interface Testing:**\\n   - Langsmith can generate a variety of text inputs, including random words, phrases, and sentences, which can be used to test the robustness of user interfaces. By inputting these generated texts into different UI fields, you can identify any potential issues, such as text overflow, improper formatting, or unexpected behavior.\\n   - You can use Langsmith to create targeted test cases. For example, you can generate specific text patterns, like long words, special characters, or localized content, to ensure that the user interface handles these cases gracefully.\\n\\n2. **Functional Testing:**\\n   - Langsmith's text generation capabilities can be leveraged to create diverse test data. By generating random but valid inputs, you can thoroughly test the functionality of your software. This helps uncover bugs, validate error handling, and ensure that the software performs as expected under various scenarios.\\n\\n3. **Localization Testing:**\\n   - If your software needs to support multiple languages, Langsmith can assist in localization testing. It can generate text in different languages, allowing you to test the accuracy of translations, proper rendering of text in various languages, and cultural adaptability.\\n\\n4. **Natural Language Processing (NLP):**\\n   - For software that incorporates NLP, such as chatbots or language understanding systems, Langsmith is invaluable. It enables you to generate a wide range of textual inputs to train and test your NLP models effectively. By exposing your models to diverse and varied text generated by Langsmith, you can improve their performance and robustness.\\n\\n5. **Edge Case Testing:**\\n   - Langsmith can help identify edge cases and boundary conditions by generating text that pushes the limits of your software. This includes generating extremely long or short inputs, text with unusual characters, or specific patterns that might impact the behavior of the software.\\n\\n6. **Performance Testing:**\\n   - By generating large volumes of text data, Langsmith can assist in performance testing. You can use this generated data to assess how your software handles high loads, stress test its capabilities, and identify any performance bottlenecks or scalability issues.\\n\\n7. **Test Case Inspiration:**\\n   - Even if you don't directly use Langsmith-generated text in your test cases, it can still provide inspiration for creating diverse and comprehensive test suites. By reviewing the generated text, you may uncover scenarios or edge cases that you hadn't previously considered.\\n\\n8. **Documentation and User Guide Testing:**\\n   - If your software includes documentation or user guides, Langsmith can help ensure their quality. By generating text snippets, you can test the clarity, accuracy, and consistency of your documentation. This includes checking for proper formatting, grammar, and the effectiveness of instructions or explanations.\\n\\nHere's an example of how you can use Langsmith for testing:\\n\\nLet's say you are developing a text editor application. With Langsmith, you can generate various text inputs to test the editor's functionality:\\n\\n- Generate paragraphs with different formatting, such as bold, italics, underline, and headings, to ensure the editor handles them correctly.\\n- Create text with special characters, emojis, and symbols to verify that the editor properly renders and handles these inputs.\\n- Simulate user inputs by generating sentences with typos, spelling errors, and grammatical mistakes to test the editor's error detection and correction features.\\n- Generate text in different languages to test the editor's ability to handle multilingual content, including proper text direction and font rendering.\\n\\nBy incorporating Langsmith-generated text into your testing process, you can identify and address issues before releasing your software, ultimately improving its quality and user experience.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '82c4950b-25ee-440c-9eec-40737297a677', 'token_count': {'input_tokens': 86, 'output_tokens': 770}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '82c4950b-25ee-440c-9eec-40737297a677', 'token_count': {'input_tokens': 86, 'output_tokens': 770}}, id='run-8ad80eb4-15e5-4061-a195-1e858858d31d-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm \n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01856be8-f712-467f-8cd0-f9ef4d0a0bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith is a powerful tool that can greatly assist with testing and quality assurance processes, especially for software products with a user interface or natural language processing capabilities. Here's how Langsmith can help with testing:\\n\\n1. **User Interface Testing:**\\n   - Internationalization and Localization: Langsmith enables you to easily translate and localize your user interface, making it possible to test your software in different languages. This helps ensure that your product works as intended for global audiences.\\n   - Pseudo-Localization: Langsmith can generate pseudo-localized text, which replaces your original text with character sets and text lengths typical of a particular language. This helps test the layout and functionality of your user interface without the need for actual translations.\\n\\n2. **Functional Testing:**\\n   - Translation Accuracy: Langsmith's translation capabilities can be leveraged to test the accuracy of translations in your software. By translating your user interface or specific test strings, you can verify that the translations are correct and contextually appropriate.\\n   - Text Rendering: Langsmith can help test how different languages and font sets are rendered in your user interface. This includes checking for text truncation, overlap, or improper formatting across various languages.\\n\\n3. **Natural Language Processing (NLP) Testing:**\\n   - Training Data Generation: Langsmith can generate synthetic text data in various languages, which can be used to train and test NLP models. This helps augment your existing training data and simulate real-world language inputs.\\n   - Model Evaluation: By generating diverse and representative text samples, Langsmith allows you to evaluate the performance of your NLP models across different languages and use cases. You can test for accuracy, bias, or edge cases that your models might encounter.\\n\\n4. **Test Case Creation:**\\n   - Langsmith's ability to generate text based on specific themes, sentiments, or topics can assist in creating test cases. You can generate text that mimics user inputs, chat messages, or support tickets, helping you prepare comprehensive test suites.\\n\\n5. **Edge Case Testing:**\\n   - Langsmith's language generation capabilities can help identify and test edge cases that might be difficult to manually create. By generating text with specific characteristics (e.g., misspellings, slang, or domain-specific jargon), you can uncover potential issues in your software's handling of natural language input.\\n\\n6. **A/B Testing:**\\n   - Langsmith can be used to create variations of text for A/B testing in marketing campaigns, user onboarding flows, or UI copy. This helps optimize your product for different languages and cultural preferences.\\n\\n7. **Documentation Testing:**\\n   - If your software includes documentation in multiple languages, Langsmith can assist in testing the accuracy and consistency of the translated documentation.\\n\\n8. **Automated Testing:**\\n   - Langsmith's API integration allows you to incorporate language generation and translation into your automated testing pipelines. This enables continuous testing and validation as part of your software development lifecycle.\\n\\nBy leveraging Langsmith's capabilities, you can streamline your testing processes, improve software quality, and ensure a positive user experience for a global audience. Remember to adapt Langsmith's output to your specific testing needs and combine it with manual testing for the best results.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | llm | \n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714a55e-0d37-418e-9f10-31ab62d32b40",
   "metadata": {},
   "source": [
    "## segunda parte do tutorial langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b510556a-6f76-4da3-a07d-0e8d4a57d6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by visualizing test results.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "\n",
    "# carega as informações do site oficial do langchain\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "#print(docs)\n",
    "\n",
    "embeddings = CohereEmbeddings()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "845e4610-0f84-47a0-a54f-5458d56350c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform that aids in the development, monitoring, and testing of LLM applications. It offers a range of features to support testing, including:\n",
      "\n",
      "- Initial Test Set: LangSmith enables developers to create datasets with input and reference output pairs, facilitating the running of tests on LLM applications. These test cases can be created, uploaded in bulk, or exported from application traces.\n",
      "- Comparison View: This feature allows users to compare the performance of different application versions by evaluating their results on the same data points side-by-side. It helps identify regressions and improvements across multiple revisions.\n",
      "- Beta Testing: LangSmith supports beta testing by capturing user feedback and allowing the annotation of traces. Feedback scores can be attached to logged traces, helping identify problematic responses. Annotating traces with respect to specific criteria provides insights into the application's performance and helps catch regressions.\n",
      "- Adding Runs to a Dataset: LangSmith allows users to expand their test coverage by adding runs as examples to datasets. This continuous data collection refines and improves the application's performance.\n",
      "- Online Evaluations and Automations: In the production phase, LangSmith offers online evaluations and automations to process and score production traces in near real-time. This provides a high-level overview of application performance, including latency, cost, and feedback scores.\n",
      "- Monitoring and A/B Testing: LangSmith provides monitoring charts to track key metrics over time. It also enables tag and metadata grouping, allowing users to compare the performance of different application versions with different identifiers.\n",
      "- Automations: This feature lets users define actions to be performed on traces in near real-time, such as automatically scoring traces, sending them to annotation queues, or adding them to datasets.\n",
      "- Threads: LangSmith offers a threads view that groups traces from a single conversation, making it easier to track the performance of multi-turn LLM applications and annotate them across multiple turns.\n",
      "\n",
      "Overall, LangSmith provides a comprehensive set of tools and features to support testing and evaluation throughout the LLM application development lifecycle.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "\n",
    "# carega as informações do site oficial do langchain\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "#print(docs)\n",
    "\n",
    "embeddings = CohereEmbeddings()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf9736-354b-4cdd-be81-df7bfc8c36c2",
   "metadata": {},
   "source": [
    "## criando um chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "077c5c77-9e49-4481-b33b-436ce1e4769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.Prototypingâ€‹Prototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing â€” and debug where it is failing â€” is incredibly important for this phase.Debuggingâ€‹When developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isnâ€™t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), itâ€™s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Setâ€‹While many developers still ship an initial version of their application based on â€œvibe checksâ€�, weâ€™ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison Viewâ€‹When prototyping different versions of your applications and making changes, itâ€™s important to see whether or not youâ€™ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, itâ€™s useful to be able to view results for different configurations on the same datapoints side-by-side. Weâ€™ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playgroundâ€‹LangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testingâ€‹Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, itâ€™s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly itâ€™s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedbackâ€‹When launching your application to an initial set of users, itâ€™s important to gather human feedback on the responses itâ€™s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Tracesâ€‹LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Datasetâ€‹As your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Productionâ€‹Closely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows youâ€™ll also want to do once your app hits production.However, especially at the production stage, itâ€™s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testingâ€‹LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period â€” this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automationsâ€‹Automations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threadsâ€‹Many LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'})],\n",
       " 'answer': 'LangSmith allows developers to create datasets that include inputs and reference outputs, which can be used to run tests on LLM applications. These test cases can be created on the fly, uploaded in bulk, or exported from application traces. LangSmith also enables developers to run custom evaluations, including LLM and heuristic-based assessments, to score test results.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c62076-3df4-48d0-be47-d161753dae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.Prototypingâ€‹Prototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing â€” and debug where it is failing â€” is incredibly important for this phase.Debuggingâ€‹When developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isnâ€™t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), itâ€™s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Setâ€‹While many developers still ship an initial version of their application based on â€œvibe checksâ€�, weâ€™ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison Viewâ€‹When prototyping different versions of your applications and making changes, itâ€™s important to see whether or not youâ€™ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, itâ€™s useful to be able to view results for different configurations on the same datapoints side-by-side. Weâ€™ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playgroundâ€‹LangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testingâ€‹Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, itâ€™s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly itâ€™s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedbackâ€‹When launching your application to an initial set of users, itâ€™s important to gather human feedback on the responses itâ€™s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Tracesâ€‹LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Datasetâ€‹As your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Productionâ€‹Closely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows youâ€™ll also want to do once your app hits production.However, especially at the production stage, itâ€™s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testingâ€‹LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period â€” this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automationsâ€‹Automations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threadsâ€‹Many LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, weâ€™ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if theyâ€™re just starting their journey.', 'language': 'en'})],\n",
       " 'answer': 'LangSmith allows developers to create datasets that include inputs and reference outputs, which can be used to run tests on LLM applications. These test cases can be created on the fly, uploaded in bulk, or exported from application traces. LangSmith also enables developers to run custom evaluations, including LLM and heuristic-based assessments, to score test results.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
